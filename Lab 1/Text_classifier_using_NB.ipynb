{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJqKHpxU-3LT"
      },
      "source": [
        "# Document Classification with Naive Bayes\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this lab session, you'll practice implementing the Naive Bayes algorithm on your own.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "In this lab you will:  \n",
        "\n",
        "* Implement document classification using Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9c9ch_g-3LX"
      },
      "source": [
        "## Import the dataset\n",
        "\n",
        "To start, import the dataset stored in the text file `SMSSpamCollection.txt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Nelj8xRj-3LY"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     class                                               text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data/SMSSpamCollection.txt', sep='\\t', header=None, names=['class', 'text'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2XEb8ow-3LZ"
      },
      "source": [
        "## Account for class imbalance\n",
        "\n",
        "To help your algorithm perform more accurately, subset the dataset so that the two classes are of equal size. To do this, keep all of the instances of the minority class (spam) and subset examples of the majority class (ham) to an equal number of examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "class\n",
              "spam    747\n",
              "ham     747\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spam_instances = df[df['class'] == 'spam']\n",
        "ham_instances = df[df['class'] == 'ham']\n",
        "\n",
        "#count the number of instances in each class\n",
        "num_spam = len(spam_instances)\n",
        "num_ham = len(ham_instances)\n",
        "\n",
        "#determine the number of instances to keep from the majority class\n",
        "num_instances_to_keep = min(num_spam, num_ham)\n",
        "\n",
        "#subset examples of the majority class to match the number of spam instances\n",
        "subset_ham = ham_instances.sample(n=num_instances_to_keep, random_state=42)\n",
        "\n",
        "#combine the selected instances of both classes\n",
        "balanced_df = pd.concat([spam_instances, subset_ham])\n",
        "\n",
        "balanced_df['class'].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySo0yR3--3La"
      },
      "source": [
        "## Train-test split\n",
        "\n",
        "Now implement a train-test split on the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DHnj1EdB-3Lb"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df['text']\n",
        "y = df['class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "train_df = pd.DataFrame({'text': X_train, 'class': y_train})\n",
        "test_df = pd.DataFrame({'text': X_test, 'class': y_test})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "##reset index\n",
        "\n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He will, you guys close?</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CAN I PLEASE COME UP NOW IMIN TOWN.DONTMATTER ...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ok k..sry i knw 2 siva..tats y i askd..</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I'll see, but prolly yeah</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'll see if I can swing by in a bit, got some ...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4452</th>\n",
              "      <td>What pa tell me.. I went to bath:-)</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4453</th>\n",
              "      <td>Jus finish watching tv... U?</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4454</th>\n",
              "      <td>Moby Pub Quiz.Win a £100 High Street prize if ...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4455</th>\n",
              "      <td>Free entry in 2 a weekly comp for a chance to ...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4456</th>\n",
              "      <td>We are at grandmas. Oh dear, u still ill? I fe...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4457 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text class\n",
              "0                              He will, you guys close?   ham\n",
              "1     CAN I PLEASE COME UP NOW IMIN TOWN.DONTMATTER ...   ham\n",
              "2               Ok k..sry i knw 2 siva..tats y i askd..   ham\n",
              "3                             I'll see, but prolly yeah   ham\n",
              "4     I'll see if I can swing by in a bit, got some ...   ham\n",
              "...                                                 ...   ...\n",
              "4452                What pa tell me.. I went to bath:-)   ham\n",
              "4453                       Jus finish watching tv... U?   ham\n",
              "4454  Moby Pub Quiz.Win a £100 High Street prize if ...  spam\n",
              "4455  Free entry in 2 a weekly comp for a chance to ...  spam\n",
              "4456  We are at grandmas. Oh dear, u still ill? I fe...   ham\n",
              "\n",
              "[4457 rows x 2 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No need to buy lunch for me.. I eat maggi mee..</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok im not sure what time i finish tomorrow but...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Waiting in e car 4 my mum lor. U leh? Reach ho...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You have won ?1,000 cash or a ?2,000 prize! To...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>If you r @ home then come down within 5 min</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1110</th>\n",
              "      <td>AH POOR BABY!HOPE URFEELING BETTERSN LUV! PROB...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1111</th>\n",
              "      <td>O ic lol. Should play 9 doors sometime yo</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1112</th>\n",
              "      <td>Ambrith..madurai..met u in arun dha marrge..re...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1113</th>\n",
              "      <td>Dear umma she called me now :-)</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1114</th>\n",
              "      <td>Dont think so. It turns off like randomlly wit...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1115 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text class\n",
              "0       No need to buy lunch for me.. I eat maggi mee..   ham\n",
              "1     Ok im not sure what time i finish tomorrow but...   ham\n",
              "2     Waiting in e car 4 my mum lor. U leh? Reach ho...   ham\n",
              "3     You have won ?1,000 cash or a ?2,000 prize! To...  spam\n",
              "4           If you r @ home then come down within 5 min   ham\n",
              "...                                                 ...   ...\n",
              "1110  AH POOR BABY!HOPE URFEELING BETTERSN LUV! PROB...   ham\n",
              "1111          O ic lol. Should play 9 doors sometime yo   ham\n",
              "1112  Ambrith..madurai..met u in arun dha marrge..re...   ham\n",
              "1113                    Dear umma she called me now :-)   ham\n",
              "1114  Dont think so. It turns off like randomlly wit...   ham\n",
              "\n",
              "[1115 rows x 2 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFX9d91o-3Lb"
      },
      "source": [
        "## Create the word frequency dictionary for each class\n",
        "\n",
        "Create a word frequency dictionary for each class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Gzndz6tE-3Lc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word frequency dictionary for spam class:\n",
            "{'FREE': 90, 'NOKIA': 12, 'Or': 3, 'Motorola': 8, 'with': 77, 'upto': 1, '12mths': 1, '1/2price': 1, 'linerental': 2, ',': 320, '500': 20, 'x-net': 1, 'mins': 18, '&': 140, '100txt/mth': 1}\n",
            "\n",
            "Word frequency dictionary for ham class:\n",
            "{'He': 42, 'will': 226, ',': 1269, 'you': 1335, 'guys': 26, 'close': 10, '?': 1077, 'CAN': 7, 'I': 1565, 'PLEASE': 2, 'COME': 3, 'UP': 13, 'NOW': 4, 'IMIN': 1, 'TOWN.DONTMATTER': 1}\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "word_freq_dict_spam = defaultdict(int)\n",
        "word_freq_dict_ham = defaultdict(int)\n",
        "\n",
        "# count word spam class\n",
        "for text in train_df[train_df['class'] == 'spam']['text']:\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        word_freq_dict_spam[word] += 1\n",
        "\n",
        "# count words for ham class\n",
        "for text in train_df[train_df['class'] == 'ham']['text']:\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        word_freq_dict_ham[word] += 1\n",
        "\n",
        "print(\"Word frequency dictionary for spam class:\")\n",
        "print(dict(list(word_freq_dict_spam.items())[:15]))  #print first 15 items\n",
        "print(\"\\nWord frequency dictionary for ham class:\")\n",
        "print(dict(list(word_freq_dict_ham.items())[:15]))  #print first 10 items for "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki1rdcIT-3Lc"
      },
      "source": [
        "## Count the total corpus words\n",
        "Calculate V, the total number of words in the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LxmH_SxM-3Lc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of unique words in the corpus (V): 11516\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "unique_words = set()\n",
        "\n",
        "#iterate through all text samples in train_df and test_df\n",
        "for text in train_df['text']:\n",
        "    words = word_tokenize(text)\n",
        "    unique_words.update(words)\n",
        "\n",
        "for text in test_df['text']:\n",
        "    words = word_tokenize(text)\n",
        "    unique_words.update(words)\n",
        "\n",
        "#calculate the total number of words in the corpus\n",
        "V = len(unique_words)\n",
        "\n",
        "print(\"Total number of unique words in the corpus (V):\", V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6kSFWqJ-3Ld"
      },
      "source": [
        "## Create a bag of words function\n",
        "\n",
        "Before implementing the entire Naive Bayes algorithm, create a helper function `bag_it()` to create a bag of words representation from a document's text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fws81RI3-3Ld"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bag of words representation: defaultdict(<class 'int'>, {'Juggling': 1, 'a': 2, 'dripping': 1, 'watermelon': 1, ',': 2, 'the': 2, 'eccentric': 1, 'violinist': 1, 'sprinted': 1, 'between': 1, 'raindrops': 1, 'his': 1, 'melody': 1, 'whimsical': 1, 'challenge': 1, 'to': 1, 'approaching': 1, 'storm': 1})\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "\n",
        "def bag_it(text):\n",
        "    #tokenize the words\n",
        "    words = word_tokenize(text)\n",
        "    \n",
        "    #initialize a defaultdict to store word frequencies\n",
        "    bag_of_words = defaultdict(int)\n",
        "    \n",
        "    #count the occurrences of each word\n",
        "    for word in words:\n",
        "        bag_of_words[word] += 1\n",
        "    \n",
        "    return bag_of_words\n",
        "\n",
        "#example\n",
        "text = \"Juggling a dripping watermelon, the eccentric violinist sprinted between raindrops, his melody a whimsical challenge to the approaching storm\"\n",
        "bag_of_words = bag_it(text)\n",
        "print(\"Bag of words representation:\", bag_of_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmoMa0-_-3Ld"
      },
      "source": [
        "## Implementing Naive Bayes\n",
        "\n",
        "Now, implement a master function to build a naive Bayes classifier. Be sure to use the logarithmic probabilities to avoid underflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yAfH3b51-3Ld"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "def classify_doc(doc, class_word_freq, p_classes, V, return_posteriors=False):\n",
        "    words = doc.split()\n",
        "    \n",
        "    # create dictionary to store class probabilities\n",
        "    class_probs = {}\n",
        "    \n",
        "    #calculate class probabilities using Naive Bayes formula\n",
        "    for label, word_freq in class_word_freq.items():\n",
        "        class_probs[label] = math.log(p_classes[label])  #initialize with prior probability\n",
        "        \n",
        "        for word in words:\n",
        "            #add Laplace smoothing for words not in the class's word frequency dictionary\n",
        "            word_freq_with_smoothing = word_freq.get(word, 0) + 1\n",
        "            #calculate the probability of the word given the class\n",
        "            word_prob = math.log(word_freq_with_smoothing / (sum(word_freq.values()) + V))\n",
        "            class_probs[label] += word_prob\n",
        "    \n",
        "    #return the class with the highest probability\n",
        "    predicted_class = max(class_probs, key=class_probs.get)\n",
        "    \n",
        "    if return_posteriors:\n",
        "        #normalize class probabilities to obtain posteriors\n",
        "        class_posteriors = {label: math.exp(prob - class_probs[predicted_class]) for label, prob in class_probs.items()}\n",
        "        return predicted_class, class_posteriors\n",
        "    else:\n",
        "        return predicted_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfiUzQB5-3Ld"
      },
      "source": [
        "## Test your classifier\n",
        "\n",
        "Finally, test your classifier and measure its accuracy. Don't be perturbed if your results are sub-par; industry use cases would require substantial additional preprocessing before implementing the algorithm in practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kSW0pfQC-3Ld"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9345291479820628\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "class_word_freq = {label: dict(bag_it(' '.join(train_df[train_df['class'] == label]['text']))) for label in train_df['class'].unique()}\n",
        "\n",
        "#create prior probabilities dictionary\n",
        "total_documents = len(train_df)\n",
        "p_classes = {label: count / total_documents for label, count in train_df['class'].value_counts().items()}\n",
        "\n",
        "#test the classifier on the test set\n",
        "correct_predictions = 0\n",
        "total_predictions = len(test_df)\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    doc = row['text']\n",
        "    true_label = row['class']\n",
        "    \n",
        "    predicted_label = classify_doc(doc, class_word_freq, p_classes, V)\n",
        "    \n",
        "    if predicted_label == true_label:\n",
        "        correct_predictions += 1\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsJGlz9s-3Ld"
      },
      "source": [
        "## Level up (Optional)\n",
        "\n",
        "Rework your code into an appropriate class structure so that you could easily implement the algorithm on any given dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOUeRY9d-3Le"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Well done! In this lab, you practiced implementing Naive Bayes for document classification!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
